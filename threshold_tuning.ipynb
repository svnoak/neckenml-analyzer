{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dance Style Classification - Threshold Tuning Notebook\n",
    "\n",
    "This notebook provides an interactive environment for:\n",
    "1. Analyzing feature distributions across dance styles\n",
    "2. Tuning classification thresholds\n",
    "3. Evaluating impact of threshold changes\n",
    "4. Visualizing decision boundaries\n",
    "\n",
    "**Workflow:**\n",
    "- Run baseline evaluation\n",
    "- Analyze misclassifications\n",
    "- Adjust thresholds interactively\n",
    "- Re-evaluate and compare metrics\n",
    "- Document successful changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import neckenml\n",
    "try:\n",
    "    from neckenml.analyzer import AudioAnalyzer\n",
    "    from neckenml.classifier import StyleClassifier\n",
    "except ImportError:\n",
    "    print(\"Error: Cannot import neckenml. Make sure it's installed.\")\n",
    "    print(\"Try: pip install -e /path/to/neckenml\")\n",
    "\n",
    "# Import evaluation utilities\n",
    "from evaluate_classification import ClassificationEvaluator\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"‚úì Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Test Data and Run Baseline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator\n",
    "evaluator = ClassificationEvaluator('test_data/test_tracks.yaml')\n",
    "\n",
    "# Load test tracks\n",
    "evaluator.load_test_data()\n",
    "\n",
    "print(f\"Loaded {len(evaluator.test_data['tracks'])} test tracks\")\n",
    "print(f\"\\nStyles represented:\")\n",
    "style_counts = pd.Series([t['true_style'] for t in evaluator.test_data['tracks']]).value_counts()\n",
    "print(style_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run baseline evaluation\n",
    "print(\"Running baseline evaluation...\\n\")\n",
    "evaluator.evaluate_all(verbose=False)\n",
    "\n",
    "# Generate metrics\n",
    "baseline_metrics = evaluator.generate_metrics()\n",
    "\n",
    "# Print report\n",
    "evaluator.print_report(baseline_metrics)\n",
    "\n",
    "# Save baseline\n",
    "evaluator.save_results('test_data/baseline_results.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Distribution Analysis\n",
    "\n",
    "Analyze how different features distribute across dance styles to identify good threshold candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from all analyzed tracks\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        'track_id': r['track_id'],\n",
    "        'true_style': r['true_style'],\n",
    "        'predicted_style': r['predicted_style'],\n",
    "        'is_correct': r['is_correct'],\n",
    "        'confidence': r['confidence'],\n",
    "        'decision_path': r['decision_path'],\n",
    "        'bpm': r['features']['bpm'],\n",
    "        'detected_meter': r['features']['detected_meter'],\n",
    "        'ternary_confidence': r['features']['ternary_confidence'],\n",
    "        'polska_score': r['features']['polska_score'],\n",
    "        'hambo_score': r['features']['hambo_score'],\n",
    "        'swing_ratio': r['features']['swing_ratio'],\n",
    "        'punchiness': r['features']['punchiness'],\n",
    "    }\n",
    "    for r in evaluator.results\n",
    "    if r.get('status') == 'analyzed'\n",
    "])\n",
    "\n",
    "print(f\"Extracted features from {len(results_df)} tracks\")\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPM distribution by style\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "styles = sorted(results_df['true_style'].unique())\n",
    "data_by_style = [results_df[results_df['true_style'] == style]['bpm'].values for style in styles]\n",
    "\n",
    "bp = ax.boxplot(data_by_style, labels=styles, patch_artist=True)\n",
    "for patch in bp['boxes']:\n",
    "    patch.set_facecolor('lightblue')\n",
    "\n",
    "ax.set_ylabel('BPM', fontsize=12, weight='bold')\n",
    "ax.set_xlabel('Dance Style', fontsize=12, weight='bold')\n",
    "ax.set_title('BPM Distribution by Dance Style', fontsize=14, weight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nBPM Statistics by Style:\")\n",
    "print(results_df.groupby('true_style')['bpm'].agg(['mean', 'std', 'min', 'max']).round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ternary confidence distribution (critical for Polska vs Polka)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# All styles\n",
    "for style in styles:\n",
    "    data = results_df[results_df['true_style'] == style]['ternary_confidence']\n",
    "    axes[0].hist(data, alpha=0.5, label=style, bins=20)\n",
    "\n",
    "axes[0].axvline(x=0.5, color='red', linestyle='--', label='Binary/Ternary boundary')\n",
    "axes[0].set_xlabel('Ternary Confidence', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_title('Ternary Confidence Distribution - All Styles', fontsize=14, weight='bold')\n",
    "axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Focus on Polska vs Polka\n",
    "polska_data = results_df[results_df['true_style'] == 'Polska']['ternary_confidence']\n",
    "polka_data = results_df[results_df['true_style'] == 'Polka']['ternary_confidence']\n",
    "\n",
    "axes[1].hist(polska_data, alpha=0.6, label='Polska (should be high)', bins=20, color='green')\n",
    "axes[1].hist(polka_data, alpha=0.6, label='Polka (should be low)', bins=20, color='red')\n",
    "axes[1].axvline(x=0.5, color='black', linestyle='--', linewidth=2, label='Decision boundary')\n",
    "axes[1].set_xlabel('Ternary Confidence', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].set_title('Ternary Confidence: Polska vs Polka', fontsize=14, weight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTernary Confidence Statistics:\")\n",
    "print(results_df.groupby('true_style')['ternary_confidence'].agg(['mean', 'std', 'min', 'max']).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polska vs Hambo score comparison (for ternary styles)\n",
    "ternary_styles = results_df[results_df['true_style'].isin(['Polska', 'Hambo', 'Vals', 'Sl√§ngpolska'])]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "for style in ['Polska', 'Hambo', 'Vals', 'Sl√§ngpolska']:\n",
    "    style_data = ternary_styles[ternary_styles['true_style'] == style]\n",
    "    if len(style_data) > 0:\n",
    "        ax.scatter(\n",
    "            style_data['polska_score'],\n",
    "            style_data['hambo_score'],\n",
    "            label=style,\n",
    "            alpha=0.7,\n",
    "            s=100\n",
    "        )\n",
    "\n",
    "# Add decision boundary lines\n",
    "ax.axhline(y=0.45, color='blue', linestyle='--', alpha=0.5, label='Hambo threshold (0.45)')\n",
    "ax.axvline(x=0.45, color='green', linestyle='--', alpha=0.5, label='Polska threshold (0.45)')\n",
    "\n",
    "# Add diagonal (where polska_score = hambo_score)\n",
    "lims = [0, max(ax.get_xlim()[1], ax.get_ylim()[1])]\n",
    "ax.plot(lims, lims, 'r--', alpha=0.5, label='Equal scores')\n",
    "\n",
    "ax.set_xlabel('Polska Score', fontsize=12, weight='bold')\n",
    "ax.set_ylabel('Hambo Score', fontsize=12, weight='bold')\n",
    "ax.set_title('Polska vs Hambo Score Distribution', fontsize=14, weight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPolska/Hambo Score Statistics:\")\n",
    "print(ternary_styles.groupby('true_style')[['polska_score', 'hambo_score']].agg(['mean', 'std']).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swing ratio distribution (for binary styles)\n",
    "binary_styles = results_df[results_df['true_style'].isin(['Polka', 'Schottis', 'Snoa', 'Engelska'])]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "for style in ['Polka', 'Schottis', 'Snoa', 'Engelska']:\n",
    "    style_data = binary_styles[binary_styles['true_style'] == style]\n",
    "    if len(style_data) > 0:\n",
    "        ax.hist(style_data['swing_ratio'], alpha=0.5, label=style, bins=15)\n",
    "\n",
    "ax.axvline(x=1.25, color='red', linestyle='--', linewidth=2, label='Schottis threshold (1.25)')\n",
    "ax.set_xlabel('Swing Ratio', fontsize=12, weight='bold')\n",
    "ax.set_ylabel('Count', fontsize=12)\n",
    "ax.set_title('Swing Ratio Distribution - Binary Styles', fontsize=14, weight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSwing Ratio Statistics:\")\n",
    "print(binary_styles.groupby('true_style')['swing_ratio'].agg(['mean', 'std', 'min', 'max']).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Error Analysis\n",
    "\n",
    "Deep dive into misclassifications to identify patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all errors\n",
    "errors_df = results_df[~results_df['is_correct']].copy()\n",
    "\n",
    "print(f\"Total errors: {len(errors_df)} / {len(results_df)} ({len(errors_df)/len(results_df):.1%})\\n\")\n",
    "\n",
    "if len(errors_df) > 0:\n",
    "    # Group by confusion pair\n",
    "    errors_df['confusion_pair'] = errors_df.apply(\n",
    "        lambda row: f\"{row['true_style']} ‚Üí {row['predicted_style']}\",\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    print(\"Most common confusions:\")\n",
    "    print(errors_df['confusion_pair'].value_counts())\n",
    "    \n",
    "    # Show error details\n",
    "    print(\"\\nError details:\")\n",
    "    print(errors_df[[\n",
    "        'track_id', 'true_style', 'predicted_style', 'confidence',\n",
    "        'decision_path', 'bpm', 'ternary_confidence'\n",
    "    ]].to_string())\n",
    "else:\n",
    "    print(\"üéâ No errors! Perfect classification!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Polska ‚Üí Polka errors specifically\n",
    "polska_to_polka = errors_df[\n",
    "    (errors_df['true_style'] == 'Polska') &\n",
    "    (errors_df['predicted_style'] == 'Polka')\n",
    "]\n",
    "\n",
    "if len(polska_to_polka) > 0:\n",
    "    print(f\"\\nPolska ‚Üí Polka errors: {len(polska_to_polka)}\")\n",
    "    print(\"\\nFeature analysis:\")\n",
    "    print(polska_to_polka[[\n",
    "        'track_id', 'bpm', 'ternary_confidence', 'polska_score',\n",
    "        'detected_meter', 'confidence'\n",
    "    ]].to_string())\n",
    "    \n",
    "    # Check if these are rescue candidates\n",
    "    print(\"\\n--- Rescue Logic Analysis ---\")\n",
    "    for _, row in polska_to_polka.iterrows():\n",
    "        print(f\"\\n{row['track_id']}:\")\n",
    "        print(f\"  Ternary confidence: {row['ternary_confidence']:.3f} (need ‚â•0.45 for rescue)\")\n",
    "        print(f\"  Polska score: {row['polska_score']:.3f} (need ‚â•0.25 for weak signal)\")\n",
    "        print(f\"  BPM: {row['bpm']:.1f} (Polska range: 95-115)\")\n",
    "        print(f\"  Detected meter: {row['detected_meter']}\")\n",
    "        \n",
    "        # Estimate rescue signals\n",
    "        signals = 0\n",
    "        if row['ternary_confidence'] >= 0.65:\n",
    "            signals += 2\n",
    "            print(f\"  ‚úì High ternary conf (+2 signals)\")\n",
    "        elif row['ternary_confidence'] >= 0.55:\n",
    "            signals += 1\n",
    "            print(f\"  ‚úì Moderate ternary conf (+1 signal)\")\n",
    "        \n",
    "        if row['polska_score'] >= 0.50:\n",
    "            signals += 2\n",
    "            print(f\"  ‚úì High polska score (+2 signals)\")\n",
    "        elif row['polska_score'] >= 0.35:\n",
    "            signals += 1\n",
    "            print(f\"  ‚úì Moderate polska score (+1 signal)\")\n",
    "        \n",
    "        if 95 <= row['bpm'] <= 115:\n",
    "            signals += 1\n",
    "            print(f\"  ‚úì In Polska BPM range (+1 signal)\")\n",
    "        \n",
    "        print(f\"  Total signals: {signals} (need ‚â•3 for rescue)\")\n",
    "        \n",
    "        if signals >= 3:\n",
    "            print(f\"  ‚ö†Ô∏è  SHOULD HAVE BEEN RESCUED! Investigate why it wasn't.\")\n",
    "        else:\n",
    "            print(f\"  ‚Üí Not enough signals for rescue\")\n",
    "else:\n",
    "    print(\"‚úì No Polska ‚Üí Polka errors!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Threshold Tuning\n",
    "\n",
    "Experiment with different threshold values and see immediate impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define current thresholds (baseline)\n",
    "THRESHOLDS = {\n",
    "    # Polska detection\n",
    "    'polska_score_min': 0.45,\n",
    "    'polska_score_weak': 0.25,\n",
    "    \n",
    "    # Hambo detection\n",
    "    'hambo_score_min': 0.45,\n",
    "    'hambo_polska_separation': 0.10,\n",
    "    \n",
    "    # Polska rescue (binary ‚Üí ternary)\n",
    "    'rescue_ternary_min': 0.45,\n",
    "    'rescue_ternary_strong': 0.65,\n",
    "    'rescue_ternary_moderate': 0.55,\n",
    "    'rescue_signals_needed': 3,\n",
    "    \n",
    "    # Binary styles\n",
    "    'schottis_swing_min': 1.25,\n",
    "    'snoa_tempo_min': 80,\n",
    "    'snoa_tempo_max': 115,\n",
    "    'polka_tempo_min': 115,\n",
    "}\n",
    "\n",
    "print(\"Current thresholds:\")\n",
    "for key, value in THRESHOLDS.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold tuning experiment template\n",
    "# Copy this cell and modify values to test different configurations\n",
    "\n",
    "# ============================================================================\n",
    "# EXPERIMENT: Reduce Polska rescue threshold\n",
    "# Hypothesis: Lower ternary_min from 0.45 to 0.42 to catch more edge cases\n",
    "# ============================================================================\n",
    "\n",
    "EXPERIMENTAL_THRESHOLDS = THRESHOLDS.copy()\n",
    "\n",
    "# Modify thresholds here\n",
    "EXPERIMENTAL_THRESHOLDS['rescue_ternary_min'] = 0.42  # Changed from 0.45\n",
    "# EXPERIMENTAL_THRESHOLDS['rescue_signals_needed'] = 2  # Uncomment to test\n",
    "\n",
    "print(\"Experimental thresholds:\")\n",
    "for key, value in EXPERIMENTAL_THRESHOLDS.items():\n",
    "    if value != THRESHOLDS[key]:\n",
    "        print(f\"  {key}: {THRESHOLDS[key]} ‚Üí {value} ‚ö†Ô∏è  CHANGED\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# TODO: Apply these thresholds to classifier and re-evaluate\n",
    "# This requires modifying the neckenml classifier to accept threshold overrides\n",
    "# For now, this serves as documentation for manual threshold changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Metrics After Changes\n",
    "\n",
    "After making threshold changes in the neckenml code, run this section to compare before/after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run evaluation after making changes\n",
    "print(\"Re-evaluating with updated thresholds...\\n\")\n",
    "\n",
    "# Create new evaluator instance to pick up code changes\n",
    "evaluator_new = ClassificationEvaluator('test_data/test_tracks.yaml')\n",
    "evaluator_new.load_test_data()\n",
    "evaluator_new.evaluate_all(verbose=False)\n",
    "\n",
    "new_metrics = evaluator_new.generate_metrics()\n",
    "evaluator_new.print_report(new_metrics)\n",
    "\n",
    "# Save updated results\n",
    "evaluator_new.save_results('test_data/updated_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline vs updated metrics\n",
    "comparison_data = []\n",
    "\n",
    "for style in baseline_metrics['per_style_accuracy'].keys():\n",
    "    baseline_acc = baseline_metrics['per_style_accuracy'].get(style, 0)\n",
    "    new_acc = new_metrics['per_style_accuracy'].get(style, 0)\n",
    "    diff = new_acc - baseline_acc\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Style': style,\n",
    "        'Baseline': baseline_acc,\n",
    "        'Updated': new_acc,\n",
    "        'Change': diff,\n",
    "        'Change_pct': diff * 100\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('Change', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BEFORE vs AFTER COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nOverall Accuracy:\")\n",
    "print(f\"  Baseline: {baseline_metrics['overall_accuracy']:.1%}\")\n",
    "print(f\"  Updated:  {new_metrics['overall_accuracy']:.1%}\")\n",
    "print(f\"  Change:   {(new_metrics['overall_accuracy'] - baseline_metrics['overall_accuracy'])*100:+.1f}%\")\n",
    "\n",
    "print(\"\\nPer-Style Accuracy Changes:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Check for regressions\n",
    "regressions = comparison_df[comparison_df['Change'] < -0.05]\n",
    "if len(regressions) > 0:\n",
    "    print(\"\\n‚ö†Ô∏è  REGRESSIONS DETECTED:\")\n",
    "    for _, row in regressions.iterrows():\n",
    "        print(f\"  {row['Style']}: {row['Change_pct']:+.1f}%\")\n",
    "else:\n",
    "    print(\"\\n‚úì No significant regressions\")\n",
    "\n",
    "# Check for improvements\n",
    "improvements = comparison_df[comparison_df['Change'] > 0.05]\n",
    "if len(improvements) > 0:\n",
    "    print(\"\\n‚úÖ IMPROVEMENTS:\")\n",
    "    for _, row in improvements.iterrows():\n",
    "        print(f\"  {row['Style']}: {row['Change_pct']:+.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, comparison_df['Baseline'], width, label='Baseline', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, comparison_df['Updated'], width, label='Updated', alpha=0.8)\n",
    "\n",
    "# Color bars based on improvement/regression\n",
    "for i, change in enumerate(comparison_df['Change']):\n",
    "    if change > 0.05:\n",
    "        bars2[i].set_color('green')\n",
    "    elif change < -0.05:\n",
    "        bars2[i].set_color('red')\n",
    "\n",
    "ax.set_ylabel('Accuracy', fontsize=12, weight='bold')\n",
    "ax.set_xlabel('Dance Style', fontsize=12, weight='bold')\n",
    "ax.set_title('Classification Accuracy: Baseline vs Updated', fontsize=14, weight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(comparison_df['Style'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.set_ylim([0, 1.1])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('test_data/threshold_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Comparison plot saved to: test_data/threshold_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Document Changes\n",
    "\n",
    "When you find improvements, document them here for tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for documenting threshold changes\n",
    "change_log_entry = {\n",
    "    'date': '2025-12-19',\n",
    "    'threshold': 'rescue_ternary_min',\n",
    "    'old_value': 0.45,\n",
    "    'new_value': 0.42,\n",
    "    'reason': 'Reduce false negatives for subtle Polska tracks',\n",
    "    'affected_test_cases': ['polska_003'],\n",
    "    'metrics_before': {\n",
    "        'polska_accuracy': baseline_metrics['per_style_accuracy'].get('Polska', 0),\n",
    "        'overall_accuracy': baseline_metrics['overall_accuracy'],\n",
    "    },\n",
    "    'metrics_after': {\n",
    "        'polska_accuracy': new_metrics['per_style_accuracy'].get('Polska', 0),\n",
    "        'overall_accuracy': new_metrics['overall_accuracy'],\n",
    "    },\n",
    "    'regression_check': {\n",
    "        'polka_accuracy_before': baseline_metrics['per_style_accuracy'].get('Polka', 0),\n",
    "        'polka_accuracy_after': new_metrics['per_style_accuracy'].get('Polka', 0),\n",
    "    },\n",
    "    'status': 'testing'  # testing | deployed | reverted\n",
    "}\n",
    "\n",
    "print(\"Change log entry:\")\n",
    "print(json.dumps(change_log_entry, indent=2))\n",
    "\n",
    "# Append to known_issues.yaml\n",
    "# (You would do this manually or with additional code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis\n",
    "\n",
    "Which features are most discriminative for each style?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap of features\n",
    "feature_cols = ['bpm', 'ternary_confidence', 'polska_score', 'hambo_score', 'swing_ratio', 'punchiness']\n",
    "correlation_matrix = results_df[feature_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "ax.set_title('Feature Correlation Matrix', fontsize=14, weight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('test_data/feature_correlation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for distinguishing styles\n",
    "# Calculate variance ratio (between-class / within-class) for each feature\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "importance_scores = {}\n",
    "\n",
    "for feature in feature_cols:\n",
    "    # Group data by style\n",
    "    groups = [results_df[results_df['true_style'] == style][feature].values \n",
    "              for style in results_df['true_style'].unique()]\n",
    "    \n",
    "    # Remove empty groups\n",
    "    groups = [g for g in groups if len(g) > 0]\n",
    "    \n",
    "    if len(groups) > 1:\n",
    "        # One-way ANOVA F-statistic\n",
    "        f_stat, p_value = f_oneway(*groups)\n",
    "        importance_scores[feature] = f_stat\n",
    "\n",
    "# Sort by importance\n",
    "importance_df = pd.DataFrame([\n",
    "    {'Feature': feature, 'F-statistic': score}\n",
    "    for feature, score in importance_scores.items()\n",
    "]).sort_values('F-statistic', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance (F-statistic from ANOVA):\")\n",
    "print(importance_df.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.barh(importance_df['Feature'], importance_df['F-statistic'], color='steelblue', alpha=0.8)\n",
    "ax.set_xlabel('F-statistic (Higher = More Discriminative)', fontsize=12, weight='bold')\n",
    "ax.set_title('Feature Importance for Style Classification', fontsize=14, weight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('test_data/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Insight: Features with high F-statistic are most useful for classification.\")\n",
    "print(\"   Focus threshold tuning on these features for maximum impact.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Use this notebook to:\n",
    "1. ‚úì Run baseline evaluation\n",
    "2. ‚úì Analyze feature distributions\n",
    "3. ‚úì Identify error patterns\n",
    "4. ‚öôÔ∏è Experiment with threshold changes\n",
    "5. ‚úì Compare before/after metrics\n",
    "6. üìù Document improvements\n",
    "\n",
    "**Next steps:**\n",
    "- Add more test tracks to increase confidence\n",
    "- Focus on critical confusions (Polska/Polka)\n",
    "- Consider ML model retraining with user feedback data\n",
    "- Implement automatic threshold optimization (grid search)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
